{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_shape</th>\n",
       "      <th>test_shape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(1458, 117)</td>\n",
       "      <td>(1459, 117)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_shape   test_shape\n",
       "0  (1458, 117)  (1459, 117)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Setup: paths, load FE data + metadata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "DATA_DIR = Path(\"../data/\")\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "ARTIFACTS_DIR = Path(\"../artifacts\")\n",
    "OOF_DIR = ARTIFACTS_DIR / \"oof\"\n",
    "SUB_DIR = ARTIFACTS_DIR / \"submissions\"\n",
    "for d in [ARTIFACTS_DIR, OOF_DIR, SUB_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_tr = pd.read_parquet(PROCESSED_DIR / \"hp_train_feat_v01.parquet\")\n",
    "df_te = pd.read_parquet(PROCESSED_DIR / \"hp_test_feat_v01.parquet\")\n",
    "with open(PROCESSED_DIR / \"hp_clean_meta_v02.json\", \"r\") as f:\n",
    "    meta = json.load(f)\n",
    "\n",
    "id_col = \"Id\"\n",
    "target_col = \"SalePrice\"\n",
    "feature_cols = [c for c in df_tr.columns if c not in [id_col, target_col]]\n",
    "\n",
    "pd.DataFrame({\"train_shape\":[df_tr.shape], \"test_shape\":[df_te.shape]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_features</th>\n",
       "      <th>n_string_cats</th>\n",
       "      <th>n_ordinals</th>\n",
       "      <th>n_cont_log1p</th>\n",
       "      <th>n_cont_yeoj</th>\n",
       "      <th>n_cont_rest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115</td>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_features  n_string_cats  n_ordinals  n_cont_log1p  n_cont_yeoj  \\\n",
       "0         115             30          15             4           15   \n",
       "\n",
       "   n_cont_rest  \n",
       "0           38  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) Column groups + dtypes (string cats vs numeric-coded cats)\n",
    "ordinal_int_cols   = meta.get(\"ordinal_int_cols\", [])\n",
    "cont_num_cols      = meta.get(\"cont_num_cols\", [])\n",
    "nominal_cols_final = meta.get(\"nominal_cols_final\", [])\n",
    "engineered_nominal = meta.get(\"engineered_nominal\", [])\n",
    "engineered_continuous = meta.get(\"engineered_continuous\", [])\n",
    "\n",
    "log1p_cols      = meta.get(\"log1p_cols\", [])\n",
    "yeojohnson_cols = meta.get(\"yeojohnson_cols\", [])\n",
    "\n",
    "for c in nominal_cols_final + engineered_nominal:\n",
    "    if c in df_tr.columns:\n",
    "        df_tr[c] = df_tr[c].astype(\"category\")\n",
    "        df_te[c] = df_te[c].astype(\"category\")\n",
    "\n",
    "def _string_cat_cols(df, cols):\n",
    "    out = []\n",
    "    for c in cols:\n",
    "        if c in df.columns and str(df[c].dtype) == \"category\":\n",
    "            cats = list(df[c].cat.categories)\n",
    "            if all(isinstance(x, str) for x in cats):\n",
    "                out.append(c)\n",
    "    return out\n",
    "\n",
    "string_cat_cols = _string_cat_cols(df_tr, nominal_cols_final + engineered_nominal)\n",
    "cont_all = [c for c in (cont_num_cols + engineered_continuous) if c in df_tr.columns]\n",
    "cont_log1p = [c for c in log1p_cols if c in cont_all]\n",
    "cont_yeoj  = [c for c in yeojohnson_cols if c in cont_all and c not in cont_log1p]\n",
    "cont_rest  = [c for c in cont_all if c not in cont_log1p + cont_yeoj]\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"n_features\":[len(feature_cols)],\n",
    "    \"n_string_cats\":[len(string_cat_cols)],\n",
    "    \"n_ordinals\":[len([c for c in ordinal_int_cols if c in df_tr.columns])],\n",
    "    \"n_cont_log1p\":[len(cont_log1p)],\n",
    "    \"n_cont_yeoj\":[len(cont_yeoj)],\n",
    "    \"n_cont_rest\":[len(cont_rest)]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>fold_random</th>\n",
       "      <th>fold_stratlog</th>\n",
       "      <th>fold_group_nbhd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  fold_random  fold_stratlog  fold_group_nbhd\n",
       "0   1            2              2                1\n",
       "1   2            4              0                3\n",
       "2   3            2              0                1\n",
       "3   4            1              1                2\n",
       "4   5            3              3                4\n",
       "5   6            1              2                1\n",
       "6   7            2              0                4\n",
       "7   8            2              3                1\n",
       "8   9            4              1                2\n",
       "9  10            2              3                3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3) Define three CV schemes: RandomKFold, StratifiedKFold(log target), GroupKFold(Neighborhood)\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\n",
    "\n",
    "y_log = np.log1p(df_tr[target_col])\n",
    "bins10 = pd.qcut(y_log, q=10, labels=False, duplicates=\"drop\")\n",
    "groups_nbhd = df_tr[\"Neighborhood\"].astype(str)\n",
    "\n",
    "n_splits = 5\n",
    "seed = 42\n",
    "\n",
    "folds_random = np.full(len(df_tr), -1, dtype=int)\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "for k, (_, val_idx) in enumerate(kf.split(df_tr)):\n",
    "    folds_random[val_idx] = k\n",
    "\n",
    "folds_strat = np.full(len(df_tr), -1, dtype=int)\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "for k, (_, val_idx) in enumerate(skf.split(y_log, bins10)):\n",
    "    folds_strat[val_idx] = k\n",
    "\n",
    "folds_group = np.full(len(df_tr), -1, dtype=int)\n",
    "gkf = GroupKFold(n_splits=n_splits)\n",
    "for k, (_, val_idx) in enumerate(gkf.split(df_tr, y_log, groups=groups_nbhd)):\n",
    "    folds_group[val_idx] = k\n",
    "\n",
    "cv_schemes = pd.DataFrame({\n",
    "    \"Id\": df_tr[id_col].values,\n",
    "    \"fold_random\": folds_random,\n",
    "    \"fold_stratlog\": folds_strat,\n",
    "    \"fold_group_nbhd\": folds_group\n",
    "})\n",
    "cv_schemes.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pipeline_ready    True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4) Build the ElasticNet preprocessing & model (same across all CV schemes)\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, PowerTransformer, FunctionTransformer, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "preproc_linear = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"log1p\", FunctionTransformer(np.log1p, validate=False), cont_log1p),\n",
    "        (\"yeo\",   PowerTransformer(method=\"yeo-johnson\", standardize=False), cont_yeoj),\n",
    "        (\"cont\",  \"passthrough\", cont_rest),\n",
    "        (\"ord\",   \"passthrough\", [c for c in ordinal_int_cols if c in df_tr.columns]),\n",
    "        (\"ohe\",   OneHotEncoder(handle_unknown=\"ignore\", min_frequency=10, sparse_output=True), string_cat_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    "    sparse_threshold=0.3,\n",
    ")\n",
    "\n",
    "elastic_pipe = Pipeline([\n",
    "    (\"pre\", preproc_linear),\n",
    "    (\"scaler\", StandardScaler(with_mean=False)),\n",
    "    (\"model\", ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=seed, max_iter=2000)),\n",
    "])\n",
    "\n",
    "pd.Series({\"pipeline_ready\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>cv_scheme</th>\n",
       "      <th>cv_rmse_mean</th>\n",
       "      <th>cv_rmse_std</th>\n",
       "      <th>oof_path</th>\n",
       "      <th>sub_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>stratlog</td>\n",
       "      <td>0.151643</td>\n",
       "      <td>0.010550</td>\n",
       "      <td>../artifacts/oof/elasticnet_stratlog_v01_oof.csv</td>\n",
       "      <td>../artifacts/submissions/elasticnet_stratlog_v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>random</td>\n",
       "      <td>0.152449</td>\n",
       "      <td>0.008862</td>\n",
       "      <td>../artifacts/oof/elasticnet_random_v01_oof.csv</td>\n",
       "      <td>../artifacts/submissions/elasticnet_random_v01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>group_nbhd</td>\n",
       "      <td>0.154661</td>\n",
       "      <td>0.046646</td>\n",
       "      <td>../artifacts/oof/elasticnet_group_nbhd_v01_oof...</td>\n",
       "      <td>../artifacts/submissions/elasticnet_group_nbhd...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model   cv_scheme  cv_rmse_mean  cv_rmse_std  \\\n",
       "1  ElasticNet    stratlog      0.151643     0.010550   \n",
       "0  ElasticNet      random      0.152449     0.008862   \n",
       "2  ElasticNet  group_nbhd      0.154661     0.046646   \n",
       "\n",
       "                                            oof_path  \\\n",
       "1   ../artifacts/oof/elasticnet_stratlog_v01_oof.csv   \n",
       "0     ../artifacts/oof/elasticnet_random_v01_oof.csv   \n",
       "2  ../artifacts/oof/elasticnet_group_nbhd_v01_oof...   \n",
       "\n",
       "                                            sub_path  \n",
       "1  ../artifacts/submissions/elasticnet_stratlog_v...  \n",
       "0  ../artifacts/submissions/elasticnet_random_v01...  \n",
       "2  ../artifacts/submissions/elasticnet_group_nbhd...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5) Run ElasticNet on all CV schemes → OOF + test + scores\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X = df_tr[feature_cols].copy()\n",
    "T = df_te[feature_cols].copy()\n",
    "\n",
    "rows_elastic = []\n",
    "for name, folds in [(\"random\", folds_random), (\"stratlog\", folds_strat), (\"group_nbhd\", folds_group)]:\n",
    "    oof = np.zeros(len(df_tr), dtype=float)\n",
    "    test_folds = []\n",
    "    fold_scores = []\n",
    "    for k in range(n_splits):\n",
    "        tr_idx = np.where(folds != k)[0]\n",
    "        va_idx = np.where(folds == k)[0]\n",
    "        _ = elastic_pipe.fit(X.iloc[tr_idx], y_log.iloc[tr_idx])\n",
    "        y_va_pred = elastic_pipe.predict(X.iloc[va_idx])\n",
    "        oof[va_idx] = y_va_pred\n",
    "        fold_scores.append(float(np.sqrt(mean_squared_error(y_log.iloc[va_idx], y_va_pred))))\n",
    "        test_folds.append(elastic_pipe.predict(T))\n",
    "    oof_df = pd.DataFrame({id_col: df_tr[id_col].values, \"pred_log\": oof})\n",
    "    oof_path = OOF_DIR / f\"elasticnet_{name}_v01_oof.csv\"\n",
    "    oof_df.to_csv(oof_path, index=False)\n",
    "\n",
    "    test_pred = np.column_stack(test_folds).mean(axis=1)\n",
    "    sub_df = pd.DataFrame({id_col: df_te[id_col].values, \"SalePrice\": np.expm1(test_pred)})\n",
    "    sub_path = SUB_DIR / f\"elasticnet_{name}_v01.csv\"\n",
    "    sub_df.to_csv(sub_path, index=False)\n",
    "\n",
    "    rows_elastic.append({\n",
    "        \"model\":\"ElasticNet\",\n",
    "        \"cv_scheme\":name,\n",
    "        \"cv_rmse_mean\": float(np.mean(fold_scores)),\n",
    "        \"cv_rmse_std\":  float(np.std(fold_scores)),\n",
    "        \"oof_path\": str(oof_path),\n",
    "        \"sub_path\": str(sub_path)\n",
    "    })\n",
    "\n",
    "elastic_scoreboard = pd.DataFrame(rows_elastic).sort_values([\"model\",\"cv_rmse_mean\"])\n",
    "elastic_scoreboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 5598\n",
      "[LightGBM] [Info] Number of data points in the train set: 1166, number of used features: 107\n",
      "[LightGBM] [Info] Start training from score 12.023362\n",
      "[LightGBM] [Info] Total Bins 5602\n",
      "[LightGBM] [Info] Number of data points in the train set: 1166, number of used features: 107\n",
      "[LightGBM] [Info] Start training from score 12.026498\n",
      "[LightGBM] [Info] Total Bins 5607\n",
      "[LightGBM] [Info] Number of data points in the train set: 1166, number of used features: 107\n",
      "[LightGBM] [Info] Start training from score 12.025399\n",
      "[LightGBM] [Info] Total Bins 5634\n",
      "[LightGBM] [Info] Number of data points in the train set: 1167, number of used features: 108\n",
      "[LightGBM] [Info] Start training from score 12.024512\n",
      "[LightGBM] [Info] Total Bins 5525\n",
      "[LightGBM] [Info] Number of data points in the train set: 1167, number of used features: 108\n",
      "[LightGBM] [Info] Start training from score 12.020308\n",
      "[LightGBM] [Info] Total Bins 5627\n",
      "[LightGBM] [Info] Number of data points in the train set: 1166, number of used features: 107\n",
      "[LightGBM] [Info] Start training from score 12.025107\n",
      "[LightGBM] [Info] Total Bins 5595\n",
      "[LightGBM] [Info] Number of data points in the train set: 1166, number of used features: 106\n",
      "[LightGBM] [Info] Start training from score 12.024424\n",
      "[LightGBM] [Info] Total Bins 5604\n",
      "[LightGBM] [Info] Number of data points in the train set: 1166, number of used features: 107\n",
      "[LightGBM] [Info] Start training from score 12.021187\n",
      "[LightGBM] [Info] Total Bins 5516\n",
      "[LightGBM] [Info] Number of data points in the train set: 1167, number of used features: 107\n",
      "[LightGBM] [Info] Start training from score 12.023079\n",
      "[LightGBM] [Info] Total Bins 5613\n",
      "[LightGBM] [Info] Number of data points in the train set: 1167, number of used features: 108\n",
      "[LightGBM] [Info] Start training from score 12.026278\n",
      "[LightGBM] [Info] Total Bins 5607\n",
      "[LightGBM] [Info] Number of data points in the train set: 1170, number of used features: 108\n",
      "[LightGBM] [Info] Start training from score 12.046949\n",
      "[LightGBM] [Info] Total Bins 5624\n",
      "[LightGBM] [Info] Number of data points in the train set: 1170, number of used features: 108\n",
      "[LightGBM] [Info] Start training from score 12.009746\n",
      "[LightGBM] [Info] Total Bins 5454\n",
      "[LightGBM] [Info] Number of data points in the train set: 1164, number of used features: 106\n",
      "[LightGBM] [Info] Start training from score 12.054844\n",
      "[LightGBM] [Info] Total Bins 5569\n",
      "[LightGBM] [Info] Number of data points in the train set: 1160, number of used features: 108\n",
      "[LightGBM] [Info] Start training from score 12.052055\n",
      "[LightGBM] [Info] Total Bins 5568\n",
      "[LightGBM] [Info] Number of data points in the train set: 1168, number of used features: 108\n",
      "[LightGBM] [Info] Start training from score 11.956765\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>cv_scheme</th>\n",
       "      <th>cv_rmse_mean</th>\n",
       "      <th>cv_rmse_std</th>\n",
       "      <th>oof_path</th>\n",
       "      <th>sub_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>random</td>\n",
       "      <td>0.121848</td>\n",
       "      <td>0.006190</td>\n",
       "      <td>../artifacts/oof/lgbm_random_v01_oof.csv</td>\n",
       "      <td>../artifacts/submissions/lgbm_random_v01.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>stratlog</td>\n",
       "      <td>0.125161</td>\n",
       "      <td>0.014441</td>\n",
       "      <td>../artifacts/oof/lgbm_stratlog_v01_oof.csv</td>\n",
       "      <td>../artifacts/submissions/lgbm_stratlog_v01.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>group_nbhd</td>\n",
       "      <td>0.135301</td>\n",
       "      <td>0.025543</td>\n",
       "      <td>../artifacts/oof/lgbm_group_nbhd_v01_oof.csv</td>\n",
       "      <td>../artifacts/submissions/lgbm_group_nbhd_v01.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model   cv_scheme  cv_rmse_mean  cv_rmse_std  \\\n",
       "0  LGBM      random      0.121848     0.006190   \n",
       "1  LGBM    stratlog      0.125161     0.014441   \n",
       "2  LGBM  group_nbhd      0.135301     0.025543   \n",
       "\n",
       "                                       oof_path  \\\n",
       "0      ../artifacts/oof/lgbm_random_v01_oof.csv   \n",
       "1    ../artifacts/oof/lgbm_stratlog_v01_oof.csv   \n",
       "2  ../artifacts/oof/lgbm_group_nbhd_v01_oof.csv   \n",
       "\n",
       "                                           sub_path  \n",
       "0      ../artifacts/submissions/lgbm_random_v01.csv  \n",
       "1    ../artifacts/submissions/lgbm_stratlog_v01.csv  \n",
       "2  ../artifacts/submissions/lgbm_group_nbhd_v01.csv  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6) LightGBM baseline across CV schemes → OOF + test + scores\n",
    "import lightgbm as lgb\n",
    "\n",
    "lgb_params = dict(\n",
    "    objective=\"regression\",\n",
    "    learning_rate=0.05,\n",
    "    n_estimators=5000,\n",
    "    num_leaves=31,\n",
    "    max_depth=-1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_lambda=0.0,\n",
    "    random_state=seed,\n",
    "    n_jobs=-1,\n",
    "    force_row_wise=True\n",
    ")\n",
    "\n",
    "rows_lgb = []\n",
    "for name, folds in [(\"random\", folds_random), (\"stratlog\", folds_strat), (\"group_nbhd\", folds_group)]:\n",
    "    oof = np.zeros(len(df_tr), dtype=float)\n",
    "    test_folds = []\n",
    "    fold_scores = []\n",
    "    for k in range(n_splits):\n",
    "        tr_idx = np.where(folds != k)[0]\n",
    "        va_idx = np.where(folds == k)[0]\n",
    "        lgbm = lgb.LGBMRegressor(**lgb_params)\n",
    "        _ = lgbm.fit(\n",
    "            X.iloc[tr_idx], y_log.iloc[tr_idx],\n",
    "            eval_set=[(X.iloc[va_idx], y_log.iloc[va_idx])],\n",
    "            eval_metric=\"rmse\",\n",
    "            callbacks=[lgb.early_stopping(200, verbose=False)],\n",
    "        )\n",
    "        y_va_pred = lgbm.predict(X.iloc[va_idx], num_iteration=lgbm.best_iteration_)\n",
    "        oof[va_idx] = y_va_pred\n",
    "        fold_scores.append(float(np.sqrt(mean_squared_error(y_log.iloc[va_idx], y_va_pred))))\n",
    "        test_folds.append(lgbm.predict(T, num_iteration=lgbm.best_iteration_))\n",
    "\n",
    "    oof_df = pd.DataFrame({id_col: df_tr[id_col].values, \"pred_log\": oof})\n",
    "    oof_path = OOF_DIR / f\"lgbm_{name}_v01_oof.csv\"\n",
    "    oof_df.to_csv(oof_path, index=False)\n",
    "\n",
    "    test_pred = np.column_stack(test_folds).mean(axis=1)\n",
    "    sub_df = pd.DataFrame({id_col: df_te[id_col].values, \"SalePrice\": np.expm1(test_pred)})\n",
    "    sub_path = SUB_DIR / f\"lgbm_{name}_v01.csv\"\n",
    "    sub_df.to_csv(sub_path, index=False)\n",
    "\n",
    "    rows_lgb.append({\n",
    "        \"model\":\"LGBM\",\n",
    "        \"cv_scheme\":name,\n",
    "        \"cv_rmse_mean\": float(np.mean(fold_scores)),\n",
    "        \"cv_rmse_std\":  float(np.std(fold_scores)),\n",
    "        \"oof_path\": str(oof_path),\n",
    "        \"sub_path\": str(sub_path)\n",
    "    })\n",
    "\n",
    "lgb_scoreboard = pd.DataFrame(rows_lgb).sort_values([\"model\",\"cv_rmse_mean\"])\n",
    "lgb_scoreboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>cv_scheme</th>\n",
       "      <th>cv_rmse_mean</th>\n",
       "      <th>cv_rmse_std</th>\n",
       "      <th>oof_path</th>\n",
       "      <th>sub_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>stratlog</td>\n",
       "      <td>0.151643</td>\n",
       "      <td>0.010550</td>\n",
       "      <td>../artifacts/oof/elasticnet_stratlog_v01_oof.csv</td>\n",
       "      <td>../artifacts/submissions/elasticnet_stratlog_v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>random</td>\n",
       "      <td>0.152449</td>\n",
       "      <td>0.008862</td>\n",
       "      <td>../artifacts/oof/elasticnet_random_v01_oof.csv</td>\n",
       "      <td>../artifacts/submissions/elasticnet_random_v01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>group_nbhd</td>\n",
       "      <td>0.154661</td>\n",
       "      <td>0.046646</td>\n",
       "      <td>../artifacts/oof/elasticnet_group_nbhd_v01_oof...</td>\n",
       "      <td>../artifacts/submissions/elasticnet_group_nbhd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>random</td>\n",
       "      <td>0.121848</td>\n",
       "      <td>0.006190</td>\n",
       "      <td>../artifacts/oof/lgbm_random_v01_oof.csv</td>\n",
       "      <td>../artifacts/submissions/lgbm_random_v01.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>stratlog</td>\n",
       "      <td>0.125161</td>\n",
       "      <td>0.014441</td>\n",
       "      <td>../artifacts/oof/lgbm_stratlog_v01_oof.csv</td>\n",
       "      <td>../artifacts/submissions/lgbm_stratlog_v01.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>group_nbhd</td>\n",
       "      <td>0.135301</td>\n",
       "      <td>0.025543</td>\n",
       "      <td>../artifacts/oof/lgbm_group_nbhd_v01_oof.csv</td>\n",
       "      <td>../artifacts/submissions/lgbm_group_nbhd_v01.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model   cv_scheme  cv_rmse_mean  cv_rmse_std  \\\n",
       "0  ElasticNet    stratlog      0.151643     0.010550   \n",
       "1  ElasticNet      random      0.152449     0.008862   \n",
       "2  ElasticNet  group_nbhd      0.154661     0.046646   \n",
       "3        LGBM      random      0.121848     0.006190   \n",
       "4        LGBM    stratlog      0.125161     0.014441   \n",
       "5        LGBM  group_nbhd      0.135301     0.025543   \n",
       "\n",
       "                                            oof_path  \\\n",
       "0   ../artifacts/oof/elasticnet_stratlog_v01_oof.csv   \n",
       "1     ../artifacts/oof/elasticnet_random_v01_oof.csv   \n",
       "2  ../artifacts/oof/elasticnet_group_nbhd_v01_oof...   \n",
       "3           ../artifacts/oof/lgbm_random_v01_oof.csv   \n",
       "4         ../artifacts/oof/lgbm_stratlog_v01_oof.csv   \n",
       "5       ../artifacts/oof/lgbm_group_nbhd_v01_oof.csv   \n",
       "\n",
       "                                            sub_path  \n",
       "0  ../artifacts/submissions/elasticnet_stratlog_v...  \n",
       "1  ../artifacts/submissions/elasticnet_random_v01...  \n",
       "2  ../artifacts/submissions/elasticnet_group_nbhd...  \n",
       "3       ../artifacts/submissions/lgbm_random_v01.csv  \n",
       "4     ../artifacts/submissions/lgbm_stratlog_v01.csv  \n",
       "5   ../artifacts/submissions/lgbm_group_nbhd_v01.csv  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7) Combined scoreboard (CV on log target). Lower is better.\n",
    "scoreboard = pd.concat([elastic_scoreboard, lgb_scoreboard], ignore_index=True)\n",
    "scoreboard.sort_values([\"model\",\"cv_rmse_mean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>cv_scheme</th>\n",
       "      <th>cv_rmse_original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>stratlog</td>\n",
       "      <td>28884.249111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>random</td>\n",
       "      <td>28976.855384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ElasticNet</td>\n",
       "      <td>group_nbhd</td>\n",
       "      <td>30138.403729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>random</td>\n",
       "      <td>24145.068535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>stratlog</td>\n",
       "      <td>25374.575672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>group_nbhd</td>\n",
       "      <td>29045.457888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        model   cv_scheme  cv_rmse_original\n",
       "0  ElasticNet    stratlog      28884.249111\n",
       "1  ElasticNet      random      28976.855384\n",
       "2  ElasticNet  group_nbhd      30138.403729\n",
       "3        LGBM      random      24145.068535\n",
       "4        LGBM    stratlog      25374.575672\n",
       "5        LGBM  group_nbhd      29045.457888"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8) (Optional) Compare on ORIGINAL Kaggle scale using OOFs (helps interpretability)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rows_orig = []\n",
    "for r in scoreboard.itertuples():\n",
    "    oof_file = Path(r.oof_path)\n",
    "    df_oof = pd.read_csv(oof_file)\n",
    "    merged = df_tr[[id_col, target_col]].merge(df_oof, on=id_col, how=\"left\")\n",
    "    rmse_orig = float(np.sqrt(mean_squared_error(merged[target_col], np.expm1(merged[\"pred_log\"]))))\n",
    "    rows_orig.append({\"model\":r.model, \"cv_scheme\":r.cv_scheme, \"cv_rmse_original\": rmse_orig})\n",
    "\n",
    "cv_original_scale = pd.DataFrame(rows_orig).sort_values([\"model\",\"cv_rmse_original\"])\n",
    "cv_original_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved selected folds to: ../data/processed/cv_folds_selected.csv\n",
      "Using folds: stratified on log target\n",
      "Folds distribution:\n",
      "fold\n",
      "0    292\n",
      "1    292\n",
      "2    292\n",
      "3    291\n",
      "4    291\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Use the stratified folds you already built as the project-default\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "PROCESSED_DIR = Path(\"../data/processed\")\n",
    "\n",
    "# Create the selected folds DataFrame from the stratified folds you already have\n",
    "folds_selected = pd.DataFrame({\n",
    "    \"Id\": df_tr[id_col].values,\n",
    "    \"fold\": folds_strat  # Use the stratified folds from earlier\n",
    "})\n",
    "\n",
    "# Save as the project default\n",
    "folds_selected.to_csv(PROCESSED_DIR / \"cv_folds_selected.csv\", index=False)\n",
    "\n",
    "print(f\"Saved selected folds to: {PROCESSED_DIR / 'cv_folds_selected.csv'}\")\n",
    "print(f\"Using folds: stratified on log target\")\n",
    "print(f\"Folds distribution:\")\n",
    "print(folds_selected['fold'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
