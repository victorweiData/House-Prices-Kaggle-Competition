{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths & logging setup (from inside notebooks/)\n",
    "from pathlib import Path\n",
    "import os, optuna, mlflow, warnings, json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Project root (one level up from notebooks/)\n",
    "PROJ_ROOT = Path(\"..\").resolve()\n",
    "\n",
    "# Canonical directories\n",
    "DATA_DIR = PROJ_ROOT / \"data\"\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "ARTIFACTS_DIR = PROJ_ROOT / \"artifacts\"\n",
    "OOF_DIR = ARTIFACTS_DIR / \"oof\"\n",
    "SUB_DIR = ARTIFACTS_DIR / \"submissions\"\n",
    "for d in [ARTIFACTS_DIR, OOF_DIR, SUB_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---- MLflow (file-based tracking at ROOT/mlruns) ----\n",
    "MLFLOW_URI = f\"file:{(PROJ_ROOT / 'mlruns').as_posix()}\"\n",
    "os.environ[\"MLFLOW_TRACKING_URI\"] = MLFLOW_URI\n",
    "mlflow.set_tracking_uri(MLFLOW_URI)\n",
    "mlflow.set_experiment(\"houseprices_lgbm\")   # change per notebook/family if you like\n",
    "\n",
    "# ---- Optuna (persistent study at ROOT/optuna_studies.db) ----\n",
    "OPTUNA_URI = f\"sqlite:///{(PROJ_ROOT / 'optuna_studies.db').as_posix()}\"\n",
    "study = optuna.create_study(\n",
    "    study_name=\"houseprices_lgbm_v01\",\n",
    "    direction=\"minimize\",\n",
    "    storage=OPTUNA_URI,\n",
    "    load_if_exists=True,\n",
    "    pruner=optuna.pruners.MedianPruner(n_warmup_steps=2),\n",
    ")\n",
    "\n",
    "# Quick visibility of resolved paths\n",
    "pd.Series({\n",
    "    \"mlflow_uri\": MLFLOW_URI,\n",
    "    \"optuna_uri\": OPTUNA_URI,\n",
    "    \"data_dir\": str(DATA_DIR),\n",
    "    \"artifacts_dir\": str(ARTIFACTS_DIR),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load engineered data + metadata + selected CV folds\n",
    "df_tr = pd.read_parquet(PROCESSED_DIR / \"hp_train_feat_v01.parquet\")\n",
    "df_te = pd.read_parquet(PROCESSED_DIR / \"hp_test_feat_v01.parquet\")\n",
    "with open(PROCESSED_DIR / \"hp_clean_meta_v02.json\", \"r\") as f:\n",
    "    meta = json.load(f)\n",
    "folds_df = pd.read_csv(PROCESSED_DIR / \"cv_folds_selected.csv\")  # stratified on log target\n",
    "\n",
    "# Basic columns\n",
    "id_col = \"Id\"\n",
    "target_col = \"SalePrice\"\n",
    "feature_cols = [c for c in df_tr.columns if c not in [id_col, target_col]]\n",
    "\n",
    "pd.DataFrame({\"train_shape\":[df_tr.shape], \"test_shape\":[df_te.shape], \"n_features\":[len(feature_cols)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Categorical & numeric feature lists (LightGBM native cats)\n",
    "# Ensure dtypes for categoricals are 'category'\n",
    "nominal_cols_final = meta.get(\"nominal_cols_final\", [])\n",
    "engineered_nominal = meta.get(\"engineered_nominal\", [])\n",
    "for c in nominal_cols_final + engineered_nominal:\n",
    "    if c in df_tr.columns:\n",
    "        df_tr[c] = df_tr[c].astype(\"category\")\n",
    "        df_te[c] = df_te[c].astype(\"category\")\n",
    "\n",
    "# cat features = category dtype columns\n",
    "cat_features = [c for c in feature_cols if str(df_tr[c].dtype) == \"category\"]\n",
    "num_features = [c for c in feature_cols if c not in cat_features]\n",
    "\n",
    "# target on log scale\n",
    "y_log = np.log1p(df_tr[target_col])\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"n_cat\":[len(cat_features)],\n",
    "    \"n_num\":[len(num_features)],\n",
    "    \"sample_cats\":[[cat_features[:10]]],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Optuna objective — Balanced-centered, safe ranges, no alias conflicts\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"objective\": \"regression\",\n",
    "        \"metric\": \"rmse\",\n",
    "\n",
    "        # LR: allow small but not glacial; early stopping will pick trees\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.2, log=True),\n",
    "\n",
    "        # Capacity: avoid ultra-shallow, cap huge leaves\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 16, 256, log=True),\n",
    "        \"max_depth\":  trial.suggest_categorical(\"max_depth\", [-1, 6, 7, 8, 9, 10]),\n",
    "\n",
    "        # Regularization via min samples per leaf (~1–15% of ~1100)\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 10, 160, log=True),\n",
    "\n",
    "        # Variance control\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"subsample\":        trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"subsample_freq\":   trial.suggest_categorical(\"subsample_freq\", [0, 1, 2]),\n",
    "\n",
    "        # L1/L2 (log spaces)\n",
    "        \"reg_alpha\":  trial.suggest_float(\"reg_alpha\", 1e-4, 10.0, log=True),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-4, 10.0, log=True),\n",
    "\n",
    "        # Gentle split penalty (near zero so we don't starve splits)\n",
    "        \"min_split_gain\": trial.suggest_float(\"min_split_gain\", 0.0, 1e-2),\n",
    "\n",
    "        # Binning: modest range for tabular FE\n",
    "        \"max_bin\": trial.suggest_int(\"max_bin\", 128, 255),\n",
    "\n",
    "        # Fixeds\n",
    "        \"n_estimators\": 10000,      # rely on early stopping\n",
    "        \"random_state\": 42,\n",
    "        \"n_jobs\": -1,\n",
    "        \"force_row_wise\": True,\n",
    "    }\n",
    "\n",
    "    # Keep leaves consistent with depth, if depth is bounded\n",
    "    if params[\"max_depth\"] != -1:\n",
    "        params[\"num_leaves\"] = int(min(params[\"num_leaves\"], 2 ** params[\"max_depth\"]))\n",
    "\n",
    "    fold_scores = []\n",
    "    for k in np.unique(fold):\n",
    "        tr_idx = np.where(fold != k)[0]\n",
    "        va_idx = np.where(fold == k)[0]\n",
    "\n",
    "        model = lgb.LGBMRegressor(**params)\n",
    "        _ = model.fit(\n",
    "            X.iloc[tr_idx], y_log.iloc[tr_idx],\n",
    "            eval_set=[(X.iloc[va_idx], y_log.iloc[va_idx])],\n",
    "            categorical_feature=cat_features,\n",
    "            callbacks=[\n",
    "                lgb.early_stopping(200, verbose=False),\n",
    "                lgb.log_evaluation(0),\n",
    "            ],\n",
    "        )\n",
    "        pred_va = model.predict(X.iloc[va_idx], num_iteration=model.best_iteration_)\n",
    "        rmse = float(np.sqrt(((y_log.iloc[va_idx] - pred_va) ** 2).mean()))\n",
    "        fold_scores.append(rmse)\n",
    "\n",
    "        trial.report(rmse, step=int(k))\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "    return float(np.mean(fold_scores))\n",
    "\n",
    "pd.Series({\"objective_ready\": True, \"study_name\": study.study_name})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Run Optuna optimization (adjust n_trials as you like) — silent training via callbacks above\n",
    "n_trials = 30\n",
    "study.optimize(objective, n_trials=n_trials, gc_after_trial=True)\n",
    "\n",
    "# Study summary (best trial)\n",
    "best = study.best_trial\n",
    "pd.DataFrame({\n",
    "    \"best_value\":[best.value],\n",
    "    \"n_trials\":[len(study.trials)],\n",
    "    \"state_counts\":[str({s: sum(t.state==s for t in study.trials) for s in set(t.state for t in study.trials)})],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Best params snapshot (sorted) — keep for configs/lgbm.yaml later\n",
    "best_params = dict(study.best_params)\n",
    "# Add fixed fields we used during tuning\n",
    "best_params.update({\"objective\":\"regression\",\"n_estimators\":10000,\"metric\":\"rmse\",\"random_state\":42,\"n_jobs\":-1})\n",
    "pd.Series(best_params).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Refit with best params to produce OOF & test predictions, and feature importance\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "oof_best = np.zeros(len(df_tr), dtype=float)\n",
    "test_folds_best = []\n",
    "fold_scores_best = []\n",
    "feat_imps = []\n",
    "\n",
    "for k in np.unique(fold):\n",
    "    tr_idx = np.where(fold != k)[0]\n",
    "    va_idx = np.where(fold == k)[0]\n",
    "\n",
    "    model = lgb.LGBMRegressor(**best_params)\n",
    "    _ = model.fit(\n",
    "        X.iloc[tr_idx], y_log.iloc[tr_idx],\n",
    "        eval_set=[(X.iloc[va_idx], y_log.iloc[va_idx])],\n",
    "        eval_metric=\"rmse\",\n",
    "        callbacks=[lgb.early_stopping(200, verbose=False)],\n",
    "        categorical_feature=cat_features,\n",
    "    )\n",
    "    pred_va = model.predict(X.iloc[va_idx], num_iteration=model.best_iteration_)\n",
    "    oof_best[va_idx] = pred_va\n",
    "    fold_scores_best.append(float(np.sqrt(mean_squared_error(y_log.iloc[va_idx], pred_va))))\n",
    "    test_folds_best.append(model.predict(T, num_iteration=model.best_iteration_))\n",
    "\n",
    "    # feature importance (gain)\n",
    "    booster = model.booster_\n",
    "    imp = pd.DataFrame({\n",
    "        \"feature\": booster.feature_name(),\n",
    "        \"gain\": booster.feature_importance(importance_type=\"gain\"),\n",
    "        \"fold\": int(k),\n",
    "    })\n",
    "    feat_imps.append(imp)\n",
    "\n",
    "cv_best = pd.DataFrame({\"fold\": sorted(np.unique(fold)), \"rmse\": fold_scores_best})\n",
    "cv_best.assign(cv_mean=float(np.mean(fold_scores_best)), cv_std=float(np.std(fold_scores_best)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Save artifacts: OOF (log), submission (expm1), feature importance\n",
    "run_tag = \"lgbm_optuna_v01\"\n",
    "oof_path = OOF_DIR / f\"{run_tag}_oof.csv\"\n",
    "sub_path = SUB_DIR / f\"{run_tag}.csv\"\n",
    "imp_path = ARTIFACTS_DIR / f\"{run_tag}_feat_importance.csv\"\n",
    "cfg_path = Path(\"../configs/lgbm.yaml\")\n",
    "\n",
    "# OOF\n",
    "pd.DataFrame({id_col: df_tr[id_col].values, \"pred_log\": oof_best}).to_csv(oof_path, index=False)\n",
    "\n",
    "# Test submission\n",
    "test_mean = np.column_stack(test_folds_best).mean(axis=1)\n",
    "pd.DataFrame({id_col: df_te[id_col].values, \"SalePrice\": np.expm1(test_mean)}).to_csv(sub_path, index=False)\n",
    "\n",
    "# Importance (average across folds)\n",
    "feat_imps_df = pd.concat(feat_imps, ignore_index=True)\n",
    "feat_imps_agg = (\n",
    "    feat_imps_df.groupby(\"feature\", as_index=False)[\"gain\"].mean().sort_values(\"gain\", ascending=False)\n",
    ")\n",
    "feat_imps_agg.to_csv(imp_path, index=False)\n",
    "\n",
    "# Config snapshot\n",
    "cfg_series = pd.Series(best_params)\n",
    "cfg_text = \"\\n\".join(f\"{k}: {v}\" for k, v in cfg_series.items())\n",
    "cfg_path.write_text(cfg_text)\n",
    "\n",
    "pd.DataFrame({\"oof\":[str(oof_path)], \"submission\":[str(sub_path)], \"feat_importance\":[str(imp_path)], \"config\":[str(cfg_path)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9) Log best run to MLflow (params, metrics, artifacts)\n",
    "cv_mean = float(np.mean(fold_scores_best))\n",
    "cv_std  = float(np.std(fold_scores_best))\n",
    "\n",
    "with mlflow.start_run(run_name=run_tag):\n",
    "    # params\n",
    "    mlflow.log_params({k: (float(v) if isinstance(v, np.floating) else v) for k, v in best_params.items()})\n",
    "    mlflow.log_param(\"folds_file\", str(PROCESSED_DIR / \"cv_folds_selected.csv\"))\n",
    "    mlflow.log_param(\"features_version\", \"feat_v01_meta_v02\")\n",
    "\n",
    "    # metrics\n",
    "    mlflow.log_metric(\"cv_rmse_mean_log\", cv_mean)\n",
    "    mlflow.log_metric(\"cv_rmse_std_log\", cv_std)\n",
    "    for r in cv_best.itertuples(index=False):\n",
    "        mlflow.log_metric(f\"fold{int(r.fold)}_rmse_log\", float(r.rmse))\n",
    "\n",
    "    # artifacts\n",
    "    mlflow.log_artifact(str(oof_path))\n",
    "    mlflow.log_artifact(str(sub_path))\n",
    "    mlflow.log_artifact(str(imp_path))\n",
    "    mlflow.log_artifact(str(cfg_path))\n",
    "\n",
    "    # tags\n",
    "    mlflow.set_tag(\"notebook\", \"notebooks/04b_lgbm.ipynb\")\n",
    "    mlflow.set_tag(\"study_name\", study.study_name)\n",
    "\n",
    "pd.DataFrame({\"cv_rmse_mean_log\":[cv_mean], \"cv_rmse_std_log\":[cv_std]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean±Std feature-importance table (all features)\n",
    "import pandas as pd\n",
    "\n",
    "feat_imps_stats = (\n",
    "    feat_imps_df\n",
    "    .groupby(\"feature\", as_index=False)[\"gain\"]\n",
    "    .agg(mean=\"mean\", std=\"std\", n_folds=\"count\")\n",
    "    .sort_values(\"mean\", ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "feat_imps_stats.head(30)  # quick peek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OOF dataframe with predictions + fold assignments\n",
    "oof_df = pd.DataFrame({\n",
    "    \"Id\": df_tr[id_col].values,\n",
    "    \"y_true_log\": y_log.values,\n",
    "    \"y_pred_log\": oof_best,\n",
    "    \"fold\": fold,\n",
    "    \"Neighborhood\": df_tr[\"Neighborhood\"].astype(str).values\n",
    "})\n",
    "\n",
    "# Residuals on log scale\n",
    "oof_df[\"resid_log\"] = oof_df[\"y_true_log\"] - oof_df[\"y_pred_log\"]\n",
    "\n",
    "# Back-transform to original scale\n",
    "oof_df[\"y_true\"] = np.expm1(oof_df[\"y_true_log\"])\n",
    "oof_df[\"y_pred\"] = np.expm1(oof_df[\"y_pred_log\"])\n",
    "oof_df[\"resid_orig\"] = oof_df[\"y_true\"] - oof_df[\"y_pred\"]\n",
    "\n",
    "oof_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.boxplot(x=\"fold\", y=\"resid_log\", data=oof_df)\n",
    "plt.axhline(0, color=\"red\", linestyle=\"--\")\n",
    "plt.title(\"Residuals (log scale) by CV fold\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# RMSE per neighborhood (original scale)\n",
    "nbhd_rmse = (\n",
    "    oof_df.groupby(\"Neighborhood\")\n",
    "    .apply(lambda g: np.sqrt(mean_squared_error(g[\"y_true\"], g[\"y_pred\"])))\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "nbhd_rmse.head(10)  # neighborhoods with worst RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(x=\"Neighborhood\", y=\"resid_orig\", data=oof_df)\n",
    "plt.axhline(0, color=\"red\", linestyle=\"--\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Residuals (original $ scale) by Neighborhood\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# mean residuals (original $) by Neighborhood × Fold\n",
    "heat_df = (\n",
    "    oof_df.groupby([\"Neighborhood\", \"fold\"])\n",
    "    .agg(mean_resid_orig=(\"resid_orig\",\"mean\"))\n",
    "    .reset_index()\n",
    "    .pivot(index=\"Neighborhood\", columns=\"fold\", values=\"mean_resid_orig\")\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(heat_df, annot=True, fmt=\".0f\", cmap=\"RdBu_r\", center=0, cbar_kws={\"label\":\"Mean Residual ($)\"})\n",
    "plt.title(\"Mean Residuals by Neighborhood × Fold\")\n",
    "plt.ylabel(\"Neighborhood\")\n",
    "plt.xlabel(\"Fold\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "heat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A) Setup: load v2 data/meta/folds, MLflow\n",
    "import numpy as np, pandas as pd, json, os, warnings\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import mlflow\n",
    "os.environ[\"MLFLOW_TRACKING_URI\"] = \"file:./mlruns\"\n",
    "mlflow.set_tracking_uri(\"file:./mlruns\")\n",
    "mlflow.set_experiment(\"houseprices_lgbm\")\n",
    "\n",
    "DATA_DIR = Path(\"../data/\")\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "ARTIFACTS_DIR = Path(\"../artifacts\")\n",
    "OOF_DIR = ARTIFACTS_DIR / \"oof\"\n",
    "SUB_DIR = ARTIFACTS_DIR / \"submissions\"\n",
    "for d in [ARTIFACTS_DIR, OOF_DIR, SUB_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# v2 feature data\n",
    "df_tr = pd.read_csv(PROCESSED_DIR / \"hp_train_feat_v02.csv\")\n",
    "df_te = pd.read_csv(PROCESSED_DIR / \"hp_test_feat_v02.csv\")\n",
    "\n",
    "# updated metadata\n",
    "with open(PROCESSED_DIR / \"hp_clean_meta_v03.json\",\"r\") as f:\n",
    "    meta = json.load(f)\n",
    "\n",
    "# folds (same file as before)\n",
    "folds_df = pd.read_csv(PROCESSED_DIR / \"cv_folds_selected.csv\")\n",
    "fold = folds_df[\"fold\"].values if \"fold\" in folds_df.columns else folds_df.iloc[:,1].values\n",
    "\n",
    "id_col = \"Id\"\n",
    "target_col = \"SalePrice\"\n",
    "feature_cols = [c for c in df_tr.columns if c not in [id_col, target_col]]\n",
    "\n",
    "pd.DataFrame({\"train_shape\":[df_tr.shape], \"test_shape\":[df_te.shape], \"n_features\":[len(feature_cols)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B) Cast categoricals for LightGBM (native cat handling)\n",
    "# Combine any nominal lists + new v2 cats; only keep columns that exist\n",
    "nominal_cols = set(meta.get(\"nominal_cols_final\", [])) \\\n",
    "               | set(meta.get(\"engineered_nominal\", [])) \\\n",
    "               | {\"Nbhd_Qual_cat_v2\",\"Nbhd_Decade_cat_v2\",\"NbhdCluster4_v2\"}\n",
    "\n",
    "cat_features = [c for c in nominal_cols if c in df_tr.columns]\n",
    "for c in cat_features:\n",
    "    df_tr[c] = df_tr[c].astype(\"category\")\n",
    "    df_te[c] = df_te[c].astype(\"category\")\n",
    "\n",
    "num_features = [c for c in feature_cols if c not in cat_features]\n",
    "y_log = np.log1p(df_tr[target_col])\n",
    "\n",
    "pd.DataFrame({\"n_cat\":[len(cat_features)], \"n_num\":[len(num_features)], \"sample_cat\":[[cat_features[:10]]]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C) Load previous best params (../configs/lgbm.yaml), or fall back to a safe baseline\n",
    "from pathlib import Path\n",
    "\n",
    "def _smart_cast(v):\n",
    "    s = str(v).strip()\n",
    "    if s.lower() in {\"true\",\"false\"}: return s.lower()==\"true\"\n",
    "    try:\n",
    "        if \".\" in s or \"e\" in s.lower(): return float(s)\n",
    "        return int(s)\n",
    "    except Exception:\n",
    "        return s\n",
    "\n",
    "cfg_path = Path(\"../configs/lgbm.yaml\")\n",
    "best_params_prev = {}\n",
    "if cfg_path.exists():\n",
    "    for line in cfg_path.read_text().splitlines():\n",
    "        if \":\" in line:\n",
    "            k, v = line.split(\":\", 1)\n",
    "            best_params_prev[k.strip()] = _smart_cast(v)\n",
    "\n",
    "# minimal required fields / overrides\n",
    "best_params = dict(best_params_prev) if best_params_prev else dict(\n",
    "    objective=\"regression\",\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=31,\n",
    "    max_depth=-1,\n",
    "    min_data_in_leaf=30,\n",
    "    feature_fraction=0.8,\n",
    "    bagging_fraction=0.8,\n",
    "    bagging_freq=1,\n",
    "    lambda_l1=0.0,\n",
    "    lambda_l2=0.0,\n",
    "    min_gain_to_split=0.0,\n",
    ")\n",
    "\n",
    "best_params.update(dict(metric=\"rmse\", n_estimators=10000, random_state=42, n_jobs=-1))\n",
    "pd.Series(best_params).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D) Refit on v2 features with the loaded params → OOF/test/importance\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X = df_tr[feature_cols].copy()\n",
    "T = df_te[feature_cols].copy()\n",
    "\n",
    "oof_v2 = np.zeros(len(df_tr), dtype=float)\n",
    "test_folds_v2 = []\n",
    "fold_scores_v2 = []\n",
    "feat_imps = []\n",
    "\n",
    "for k in np.unique(fold):\n",
    "    tr_idx = np.where(fold != k)[0]\n",
    "    va_idx = np.where(fold == k)[0]\n",
    "\n",
    "    model = lgb.LGBMRegressor(**best_params)\n",
    "    _ = model.fit(\n",
    "        X.iloc[tr_idx], y_log.iloc[tr_idx],\n",
    "        eval_set=[(X.iloc[va_idx], y_log.iloc[va_idx])],\n",
    "        eval_metric=\"rmse\",\n",
    "        callbacks=[lgb.early_stopping(200, verbose=False)],\n",
    "        categorical_feature=cat_features,\n",
    "    )\n",
    "    pred_va = model.predict(X.iloc[va_idx], num_iteration=model.best_iteration_)\n",
    "    oof_v2[va_idx] = pred_va\n",
    "    fold_scores_v2.append(float(np.sqrt(mean_squared_error(y_log.iloc[va_idx], pred_va))))\n",
    "    test_folds_v2.append(model.predict(T, num_iteration=model.best_iteration_))\n",
    "\n",
    "    booster = model.booster_\n",
    "    imp = pd.DataFrame({\n",
    "        \"feature\": booster.feature_name(),\n",
    "        \"gain\": booster.feature_importance(importance_type=\"gain\"),\n",
    "        \"fold\": int(k),\n",
    "    })\n",
    "    feat_imps.append(imp)\n",
    "\n",
    "cv_v2 = pd.DataFrame({\"fold\": sorted(np.unique(fold)), \"rmse\": fold_scores_v2})\n",
    "cv_v2.assign(cv_mean=float(np.mean(fold_scores_v2)), cv_std=float(np.std(fold_scores_v2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E) Save artifacts under a new v02 tag + log to MLflow\n",
    "run_tag = \"lgbm_v02_refit_prevbest\"\n",
    "from pathlib import Path\n",
    "\n",
    "oof_path = OOF_DIR / f\"{run_tag}_oof.csv\"\n",
    "sub_path = SUB_DIR / f\"{run_tag}.csv\"\n",
    "imp_path = ARTIFACTS_DIR / f\"{run_tag}_feat_importance.csv\"\n",
    "\n",
    "# OOF (log)\n",
    "pd.DataFrame({id_col: df_tr[id_col].values, \"pred_log\": oof_v2}).to_csv(oof_path, index=False)\n",
    "\n",
    "# Test submission (expm1 of mean over folds)\n",
    "test_mean = np.column_stack(test_folds_v2).mean(axis=1)\n",
    "pd.DataFrame({id_col: df_te[id_col].values, \"SalePrice\": np.expm1(test_mean)}).to_csv(sub_path, index=False)\n",
    "\n",
    "# Importance (mean over folds)\n",
    "feat_imps_df = pd.concat(feat_imps, ignore_index=True)\n",
    "feat_imps_agg = (\n",
    "    feat_imps_df.groupby(\"feature\", as_index=False)[\"gain\"].mean().sort_values(\"gain\", ascending=False)\n",
    ")\n",
    "feat_imps_agg.to_csv(imp_path, index=False)\n",
    "\n",
    "# MLflow logging\n",
    "cv_mean = float(np.mean(fold_scores_v2))\n",
    "cv_std  = float(np.std(fold_scores_v2))\n",
    "\n",
    "with mlflow.start_run(run_name=run_tag):\n",
    "    mlflow.log_params({k: (float(v) if isinstance(v, (np.floating,)) else v) for k, v in best_params.items()})\n",
    "    mlflow.log_param(\"feature_version\", \"v02\")\n",
    "    mlflow.log_param(\"folds_file\", str(PROCESSED_DIR / \"cv_folds_selected.csv\"))\n",
    "    mlflow.log_metric(\"cv_rmse_mean_log\", cv_mean)\n",
    "    mlflow.log_metric(\"cv_rmse_std_log\", cv_std)\n",
    "    for r in cv_v2.itertuples(index=False):\n",
    "        mlflow.log_metric(f\"fold{int(r.fold)}_rmse_log\", float(r.rmse))\n",
    "    mlflow.log_artifact(str(oof_path))\n",
    "    mlflow.log_artifact(str(sub_path))\n",
    "    mlflow.log_artifact(str(imp_path))\n",
    "\n",
    "pd.DataFrame({\"cv_rmse_mean_log\":[cv_mean], \"cv_rmse_std_log\":[cv_std], \"oof\":[str(oof_path)], \"submission\":[str(sub_path)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# --- Step 1: Ensure target log column exists\n",
    "df_tr[\"SalePrice_log\"] = np.log1p(df_tr[\"SalePrice\"])\n",
    "\n",
    "# --- Step 2: Build stratification strata\n",
    "nbhd_price = df_tr.groupby(\"Neighborhood\")[\"SalePrice_log\"].median()\n",
    "nbhd_tier  = pd.qcut(nbhd_price, q=4, labels=False)\n",
    "\n",
    "df_tr[\"nbhd_tier\"] = df_tr[\"Neighborhood\"].map(nbhd_tier)\n",
    "df_tr[\"price_bin\"] = pd.qcut(df_tr[\"SalePrice_log\"], q=10, labels=False)\n",
    "\n",
    "# Combine neighborhood tier + price bin\n",
    "df_tr[\"strata\"] = df_tr[\"nbhd_tier\"].astype(str) + \"_\" + df_tr[\"price_bin\"].astype(str)\n",
    "\n",
    "# --- Step 3: StratifiedKFold on strata\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "df_tr[\"fold\"] = -1\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(df_tr, df_tr[\"strata\"])):\n",
    "    df_tr.loc[val_idx, \"fold\"] = fold\n",
    "\n",
    "# --- Step 4: Check balance\n",
    "print(df_tr[\"fold\"].value_counts())\n",
    "print(df_tr.groupby(\"fold\")[\"SalePrice_log\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# --- Ensure processed dir exists ---\n",
    "PROCESSED_DIR = DATA_DIR / \"processed\"\n",
    "PROCESSED_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- Save folds file ---\n",
    "folds_path = PROCESSED_DIR / \"cv_folds_strat_nbhd_price_v01.csv\"\n",
    "df_tr[[\"Id\", \"fold\"]].to_csv(folds_path, index=False)\n",
    "\n",
    "print(f\"Saved folds to: {folds_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
